{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FoodGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RavenPillmann/foodgan/blob/master/FoodGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyJ9GzpUMU5D",
        "colab_type": "code",
        "outputId": "8c91f15c-917d-4bd9-b523-2e670e15651a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, Reshape\n",
        "from keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "%pylab inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKNemFP5Gi3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "project_id = \"recipe2image-244621\"\n",
        "import os\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = project_id\n",
        "client = storage.Client(project=project_id)\n",
        "bucket = client.get_bucket('recipes-with-images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzcxLgiPAa2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('./images.zip', 'r')\n",
        "zip_ref.extractall(\"./images\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xDrRzC3MYd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator(input_layer):\n",
        "  '''\n",
        "  Requires the input layer as input, outputs the model and the final layer\n",
        "  '''\n",
        "  \n",
        "  hid = Dense(128 * 32 * 32, activation='relu')(input_layer)    \n",
        "  hid = BatchNormalization(momentum=0.9)(hid)\n",
        "  hid = LeakyReLU(alpha=0.1)(hid)\n",
        "  hid = Reshape((32, 32, 128))(hid)\n",
        "\n",
        "  hid = Conv2D(128, kernel_size=5, strides=1,padding='same')(hid)\n",
        "  hid = BatchNormalization(momentum=0.9)(hid)    \n",
        "  #hid = Dropout(0.5)(hid)\n",
        "  hid = LeakyReLU(alpha=0.1)(hid)\n",
        "\n",
        "  hid = Conv2DTranspose(128, 4, strides=4, padding='same')(hid)\n",
        "  hid = BatchNormalization(momentum=0.9)(hid)\n",
        "  hid = LeakyReLU(alpha=0.1)(hid)\n",
        "\n",
        "#   hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n",
        "#   hid = BatchNormalization(momentum=0.9)(hid)\n",
        "#   #hid = Dropout(0.5)(hid)\n",
        "#   hid = LeakyReLU(alpha=0.1)(hid)\n",
        "  \n",
        "  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n",
        "  hid = BatchNormalization(momentum=0.9)(hid)\n",
        "  #hid = Dropout(0.5)(hid)\n",
        "  hid = LeakyReLU(alpha=0.1)(hid)\n",
        "  \n",
        "#   hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n",
        "#   hid = BatchNormalization(momentum=0.9)(hid)\n",
        "#   hid = LeakyReLU(alpha=0.1)(hid)\n",
        "\n",
        "  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n",
        "  hid = BatchNormalization(momentum=0.9)(hid)\n",
        "  #hid = Dropout(0.5)(hid)\n",
        "  hid = LeakyReLU(alpha=0.1)(hid)\n",
        "  \n",
        "  \n",
        "#   hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n",
        "#   hid = BatchNormalization(momentum=0.9)(hid)\n",
        "#   hid = LeakyReLU(alpha=0.1)(hid)\n",
        "\n",
        "#   hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n",
        "#   hid = BatchNormalization(momentum=0.9)(hid)\n",
        "#   #hid = Dropout(0.5)(hid)\n",
        "#   hid = LeakyReLU(alpha=0.1)(hid)\n",
        "\n",
        "#   hid = Conv2D(64, kernel_size=5, strides=1, padding='same')(hid)\n",
        "#   hid = BatchNormalization(momentum=0.9)(hid)\n",
        "#   hid = LeakyReLU(alpha=0.1)(hid)\n",
        "                      \n",
        "  hid = Conv2D(3, kernel_size=5, strides=1, padding=\"same\")(hid)\n",
        "  out = Activation(\"tanh\")(hid)\n",
        "\n",
        "  model = Model(input_layer, out)\n",
        "  model.summary()\n",
        "  \n",
        "  return model, out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok-9WdgJMbPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_discriminator(input_layer):\n",
        "  '''\n",
        "  Requires the input layer as input, outputs the model and the final layer\n",
        "  '''\n",
        "\n",
        "  hid = Conv2D(128, kernel_size=3, strides=1, padding='same')(input_layer)\n",
        "  hid = BatchNormalization(momentum=0.9)(hid)\n",
        "  hid = LeakyReLU(alpha=0.1)(hid)\n",
        "\n",
        "  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
        "  hid = BatchNormalization(momentum=0.9)(hid)\n",
        "  hid = LeakyReLU(alpha=0.1)(hid)\n",
        "\n",
        "  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
        "  hid = BatchNormalization(momentum=0.9)(hid)\n",
        "  hid = LeakyReLU(alpha=0.1)(hid)\n",
        "\n",
        "  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
        "  hid = BatchNormalization(momentum=0.9)(hid)\n",
        "  hid = LeakyReLU(alpha=0.1)(hid)\n",
        "\n",
        "  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
        "  hid = BatchNormalization(momentum=0.9)(hid)\n",
        "  hid = LeakyReLU(alpha=0.1)(hid)\n",
        "  \n",
        "#   hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
        "#   hid = BatchNormalization(momentum=0.9)(hid)\n",
        "#   hid = LeakyReLU(alpha=0.1)(hid)\n",
        "  \n",
        "  hid = Flatten()(hid)\n",
        "  hid = Dropout(0.4)(hid)\n",
        "  out = Dense(69, activation='sigmoid')(hid)\n",
        "\n",
        "  model = Model(input_layer, out)\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model, out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUuvB66kMdvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "def generate_noise(n_samples, noise_dim):\n",
        "  X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n",
        "  return X\n",
        "\n",
        "def show_imgs(batchidx):\n",
        "  noise = generate_noise(9, 100)\n",
        "  input_class_section = np.ones((9, 19))\n",
        "  ingreds = np.random.randint(0, 2, [9, 50])\n",
        "  classes = np.random.randint(0, 19, 9)\n",
        "  print(\"Classes\", classes)\n",
        "  for i in range(9):\n",
        "    input_class_section[i, classes[i]] = 0\n",
        "    \n",
        "  input_class_section = np.hstack((input_class_section, ingreds))\n",
        "  \n",
        "  noise = np.hstack((noise, input_class_section))\n",
        "  \n",
        "  gen_imgs = generator.predict(noise)\n",
        "\n",
        "  fig, axs = plt.subplots(3, 3)\n",
        "  count = 0\n",
        "  for i in range(3):\n",
        "    for j in range(3):\n",
        "      # Dont scale the images back, let keras handle it\n",
        "      img = image.array_to_img(gen_imgs[count], scale=True)\n",
        "      axs[i,j].imshow(img)\n",
        "      axs[i,j].axis('off')\n",
        "      count += 1\n",
        "  plt.show()\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKv8JS0vMlYc",
        "colab_type": "code",
        "outputId": "9ad1baaf-0b8f-4e39-d804-d2cbe6ec357c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# GAN creation\n",
        "img_input = Input(shape=(128, 128, 3))\n",
        "discriminator, disc_out = get_discriminator(img_input)\n",
        "discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "discriminator.trainable = False\n",
        "\n",
        "noise_input = Input(shape=(169,))\n",
        "generator, gen_out = get_generator(noise_input)\n",
        "\n",
        "gan_input = Input(shape=(169,))\n",
        "x = generator(gan_input)\n",
        "gan_out = discriminator(x)\n",
        "gan = Model(gan_input, gan_out)\n",
        "gan.summary()\n",
        "\n",
        "gan.compile(optimizer=Adam(0.0002, 0.5), loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 13:55:24.969257 140107080402816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0723 13:55:24.984706 140107080402816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0723 13:55:24.988671 140107080402816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0723 13:55:25.013918 140107080402816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0723 13:55:25.015091 140107080402816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0723 13:55:25.815372 140107080402816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0723 13:55:26.310856 140107080402816 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0723 13:55:26.354821 140107080402816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 128)     3584      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 128)       262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 128)       262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 128)       262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 69)                565317    \n",
            "=================================================================\n",
            "Total params: 1,620,549\n",
            "Trainable params: 1,619,269\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 169)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 131072)            22282240  \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 131072)            524288    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 128)       409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 128, 128, 128)     262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 128, 128, 128)     409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 128, 128, 128)     409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 128, 128, 3)       9603      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128, 128, 3)       0         \n",
            "=================================================================\n",
            "Total params: 24,309,635\n",
            "Trainable params: 24,046,467\n",
            "Non-trainable params: 263,168\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 169)               0         \n",
            "_________________________________________________________________\n",
            "model_2 (Model)              (None, 128, 128, 3)       24309635  \n",
            "_________________________________________________________________\n",
            "model_1 (Model)              (None, 69)                1620549   \n",
            "=================================================================\n",
            "Total params: 25,930,184\n",
            "Trainable params: 24,046,467\n",
            "Non-trainable params: 1,883,717\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64YbiUhxHe0p",
        "colab_type": "code",
        "outputId": "5b7b04d4-53c9-4021-9f62-a0e0154aea87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# GAN LOADING\n",
        "from keras.models import load_model\n",
        "\n",
        "img_input = Input(shape=(128, 128, 3))\n",
        "discriminator, disc_out = get_discriminator(img_input)\n",
        "discriminator = load_model('all_ingredient_gan_disc_biggest_52.h5')\n",
        "discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "discriminator.trainable = False\n",
        "\n",
        "noise_input = Input(shape=(169,))\n",
        "generator, gen_out = get_generator(noise_input)\n",
        "generator = load_model('all_ingredient_gan_gen_biggest_52.h5')\n",
        "\n",
        "gan_input = Input(shape=(169,))\n",
        "x = generator(gan_input)\n",
        "gan_out = discriminator(x)\n",
        "gan = Model(gan_input, gan_out)\n",
        "gan.summary()\n",
        "\n",
        "gan.compile(optimizer=Adam(0.0002, 0.5), loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 16:03:36.120483 140414929508224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0725 16:03:36.169294 140414929508224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0725 16:03:36.177793 140414929508224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0725 16:03:36.231727 140414929508224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0725 16:03:36.233385 140414929508224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0725 16:03:39.169666 140414929508224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0725 16:03:39.715937 140414929508224 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 128)     3584      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 128)       262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 128)       262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 128)       262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 69)                565317    \n",
            "=================================================================\n",
            "Total params: 1,620,549\n",
            "Trainable params: 1,619,269\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0725 16:03:40.980633 140414929508224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0725 16:03:41.115777 140414929508224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 169)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 131072)            22282240  \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 131072)            524288    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 128)       409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 128, 128, 128)     262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 128, 128, 128)     409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 128, 128, 128)     409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 128, 128, 3)       9603      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128, 128, 3)       0         \n",
            "=================================================================\n",
            "Total params: 24,309,635\n",
            "Trainable params: 24,046,467\n",
            "Non-trainable params: 263,168\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 169)               0         \n",
            "_________________________________________________________________\n",
            "model_2 (Model)              (None, 128, 128, 3)       24309635  \n",
            "_________________________________________________________________\n",
            "model_1 (Model)              (None, 69)                1620549   \n",
            "=================================================================\n",
            "Total params: 25,930,184\n",
            "Trainable params: 24,046,467\n",
            "Non-trainable params: 1,883,717\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-YOGO1eOMOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "def loadTrainingData(indices, batch_size):\n",
        "\traw_imgs = []\n",
        "\tapplicable_indices = []\n",
        "\n",
        "# \tfilepaths = ['./vegetable_images/vegetable_images/'+str(name)+'.jpg' for name in indices]\n",
        "# \tfilepaths = ['./noodle_pasta_augmented_images/noodle_pasta_augmented_images/'+str(name)+'.jpg' for name in indices]\n",
        "\tfilepaths = ['./images/images/'+str(name)+'.jpg' for name in indices]\n",
        "\tnames = [int(name) for name in indices]\n",
        "  \n",
        "\tfor i in range(len(filepaths)):\n",
        "\t\tfilepath = filepaths[i]\n",
        "\t\tname = names[i]\n",
        "\t\timage = cv2.imread(filepath)\n",
        "\n",
        "\t\tif (not isinstance(image, type(None))):\n",
        "\t\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\t\t\traw_imgs.append(image)\n",
        "\t\t\tapplicable_indices.append(name)\n",
        "\t\tif len(raw_imgs) == batch_size:\n",
        "\t\t\tbreak\n",
        "\n",
        "\timg_tensors = [cv2.resize((raw_img - 127.5) / 127.5, (128, 128)) for raw_img in raw_imgs]\n",
        "\n",
        "\treturn np.array(img_tensors), np.array(applicable_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un1l_35tnkcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def loadAllTrainingY(filepath):\n",
        "\ty_train = {}\n",
        "\n",
        "\twith open(filepath, 'r') as input_file:\n",
        "\t\tcsv_reader = csv.reader(input_file, delimiter=\",\")\n",
        "\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\t_id = int(row[0])\n",
        "\t\t\tone_hot_encoded = row[1:]\n",
        "\t\t\ty_train[_id] = np.array(one_hot_encoded[:69])\n",
        "      \n",
        "\tmax_y = max(y_train.keys())\n",
        "  \n",
        "\ty = np.ones((max_y+1, 69))\n",
        "\n",
        "\tfor i in y_train.keys():\n",
        "\t\ty[i, :] = y_train[i]\n",
        "  \n",
        "\treturn y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFa5Xt0gMrAl",
        "colab_type": "code",
        "outputId": "dc7d071c-e3d1-44ae-e4ea-88163b82d0c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import os\n",
        "\n",
        "os.system(\"mkdir saved_gen_models_all_biggest\")\n",
        "os.system(\"mkdir saved_disc_models_all_biggest\")\n",
        "number_of_images = len(os.listdir(\"./images/images\"))\n",
        "\n",
        "y_train = loadAllTrainingY(\"data_one_hot.csv\")\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "num_batches = int(number_of_images/BATCH_SIZE)\n",
        "\n",
        "N_EPOCHS = 160\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  cum_d_loss = 0.\n",
        "  cum_g_loss = 0.\n",
        "  \n",
        "  for batch_idx in range(num_batches):\n",
        "    # Get the next set of real images to be used in this iteration\n",
        "    indices = np.random.randint(0, number_of_images, size=3*BATCH_SIZE) # Get triple the indices just to be safe\n",
        "    images, applicable_indices = loadTrainingData(indices, BATCH_SIZE)\n",
        "    y_vals = y_train[applicable_indices, :]\n",
        "    \n",
        "    # TODO: Make fake y_vals for the generated data\n",
        "    generated_y_vals = np.ones((BATCH_SIZE, 19))\n",
        "    random_ints = np.random.randint(0, 19, BATCH_SIZE)\n",
        "    ingreds = np.random.randint(0, 2, [BATCH_SIZE, 50])\n",
        "    for ind in range(BATCH_SIZE):\n",
        "      rand_ind = random_ints[ind]\n",
        "      generated_y_vals[ind, rand_ind] = 0\n",
        "    generated_y_vals = np.hstack((generated_y_vals, ingreds))\n",
        "\n",
        "    noise_data = generate_noise(BATCH_SIZE, 100)\n",
        "    \n",
        "    input_data = np.hstack((noise_data, 1 - generated_y_vals))\n",
        "    \n",
        "    generated_images = generator.predict(input_data)\n",
        "\n",
        "    # Train on soft labels (add noise to labels as well)\n",
        "    noise_prop = 0.05 # Randomly flip 5% of labels\n",
        "    \n",
        "    # TODO: append real y_vals to real data\n",
        "    \n",
        "    true_labels = 1 - y_vals\n",
        "    true_labels = np.abs(true_labels - np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 69)))\n",
        "    flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n",
        "    true_labels[flipped_idx, :] = 1 - true_labels[flipped_idx, :]\n",
        "    \n",
        "    # Prepare labels for real data\n",
        "#     true_labels = np.zeros((BATCH_SIZE, 1)) + np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n",
        "#     flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n",
        "#     true_labels[flipped_idx] = 1 - true_labels[flipped_idx]\n",
        "    \n",
        "    # Train discriminator on real data\n",
        "    d_loss_true = discriminator.train_on_batch(images, true_labels)\n",
        "\n",
        "    gene_labels = np.ones((BATCH_SIZE, 69)) - np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 69))\n",
        "    flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop * len(gene_labels)))\n",
        "#     print(gene_labels.shape, flipped_idx.shape)\n",
        "    gene_labels[flipped_idx, :] = 1 - gene_labels[flipped_idx, :]\n",
        "                            \n",
        "    # Prepare labels for generated data\n",
        "#     gene_labels = np.ones((BATCH_SIZE, 1)) - np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n",
        "#     flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop*len(gene_labels)))\n",
        "#     gene_labels[flipped_idx] = 1 - gene_labels[flipped_idx]\n",
        "    \n",
        "    # Train discriminator on generated data\n",
        "    d_loss_gene = discriminator.train_on_batch(generated_images, gene_labels)\n",
        "\n",
        "    d_loss = 0.5 * np.add(d_loss_true, d_loss_gene)\n",
        "    cum_d_loss += d_loss\n",
        "\n",
        "    # Train generator\n",
        "    noise_data = generate_noise(BATCH_SIZE, 100)\n",
        "    noise_data = np.hstack((noise_data, 1 - generated_y_vals))\n",
        "#     g_loss = gan.train_on_batch(noise_data, np.zeros((BATCH_SIZE, 1)))\n",
        "    g_loss = gan.train_on_batch(noise_data, 1 - generated_y_vals)\n",
        "    cum_g_loss += g_loss\n",
        "\n",
        "  print('  Epoch: {}, Generator Loss: {}, Discriminator Loss: {}'.format(epoch+1, cum_g_loss/num_batches, cum_d_loss/num_batches))\n",
        "  show_imgs(\"epoch\" + str(epoch))\n",
        "  file_name = \"saved_gen_models_all_biggest/\" + str(epoch + 1 + 52) + \"_np_gen.h5\"\n",
        "  generator.save(file_name)\n",
        "  file_name_disc = \"saved_disc_models_all_biggest/\" + str(epoch + 1 + 52) + \"_np_disc.h5\"\n",
        "  discriminator.save(file_name_disc)\n",
        "  \n",
        "  os.system(\"gsutil cp -r saved_gen_models_all_biggest/\" + str(epoch + 1 + 52) + \"_np_gen.h5 gs://recipes-with-images/all_ingredient_gan/gen_biggest/\"+str(epoch+1 + 52)+\".h5\")\n",
        "  os.system(\"gsutil cp -r saved_disc_models_all_biggest/\" + str(epoch + 1 + 52) + \"_np_disc.h5 gs://recipes-with-images/all_ingredient_gan/disc_biggest/\"+str(epoch+1 + 52)+\".h5\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymBukKaGQ86l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # NOTE: Last saved epoch 17"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn1q3oNFMuTU",
        "colab_type": "code",
        "outputId": "e7ebbf6d-86df-4cab-8521-505881c5bd36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        }
      },
      "source": [
        "# Upgrade\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "gen_model = load_model('all_ingredient_gan_gen_160.h5')\n",
        "\n",
        "gen_model.layers.pop()\n",
        "gen_model.layers.pop()\n",
        "\n",
        "gen_model = Conv2DTranspose(128, 4, strides=2, padding='same')(gen_model)\n",
        "gen_model = BatchNormalization(momentum=0.9)(gen_model)\n",
        "gen_model = LeakyReLU(alpha=0.1)(gen_model)\n",
        "\n",
        "gen_model = Conv2D(128, kernel_size=5, strides=1, padding='same')(gen_model)\n",
        "gen_model = BatchNormalization(momentum=0.9)(gen_model)\n",
        "  #hid = Dropout(0.5)(hid)\n",
        "gen_model = LeakyReLU(alpha=0.1)(gen_model)\n",
        "\n",
        "gen_model = Conv2D(3, kernel_size=5, strides=1, padding=\"same\")(gen_model)\n",
        "out = Activation(\"tanh\")(gen_model)\n",
        "\n",
        "generator = Model(generator.input, generator.output)\n",
        "\n",
        "disc_model = load_model('all_ingredient_gan_disc_160.h5')\n",
        "\n",
        "disc_model.layers.pop()\n",
        "disc_model.layers.pop()\n",
        "disc_model.layers.pop()\n",
        "\n",
        "disc_model = Conv2D(128, kernel_size=4, strides=2, padding='same')(disc_model)\n",
        "disc_model = BatchNormalization(momentum=0.9)(disc_model)\n",
        "disc_model = LeakyReLU(alpha=0.1)(disc_model)\n",
        "\n",
        "disc_model = Flatten()(disc_model)\n",
        "disc_model = Dropout(0.4)(disc_model)\n",
        "out = Dense(69, activation='sigmoid')(disc_model)\n",
        "\n",
        "disc_model = Model(disc_model.input, out)\n",
        "\n",
        "img_input = Input(shape=(32, 32, 3))\n",
        "disc_model.compile(optimizer=Adam(0.0002, 0.5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "disc_model.trainable = False\n",
        "\n",
        "noise_input = Input(shape=(119,))\n",
        "\n",
        "gan_input = Input(shape=(119,))\n",
        "x = gen_model(gan_input)\n",
        "gan_out = disc_model(x)\n",
        "gan = Model(gan_input, gan_out)\n",
        "gan.summary()\n",
        "\n",
        "gan.compile(optimizer=Adam(0.0002, 0.5), loss='categorical_crossentropy')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    473\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 474\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                          'Expected a symbolic tensor instance.')\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'keras.engine.training.Model'>`. Expected a symbolic tensor instance.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-76489679046b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgen_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgen_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mgen_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgen_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer conv2d_transpose_3 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.engine.training.Model'>. Full input: [<keras.engine.training.Model object at 0x7fb0e12a3c50>]. All inputs to the layer should be tensors."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5lVM7WmTLah",
        "colab_type": "code",
        "outputId": "298a1559-78f8-445c-8e18-95b37c699c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-05bf4bd94994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-2656e61b7102>\u001b[0m in \u001b[0;36mshow_imgs\u001b[0;34m(batchidx)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;31m# Dont scale the images back, let keras handle it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'array_to_img'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz8209HFTmfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}